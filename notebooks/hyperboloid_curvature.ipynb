{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Gaussian curvature with Pytorch\n",
    "adapted from https://github.com/jamesgolden1/bias_free_denoising/blob/manifold_metric/curvature/hyperboloid_single_sheet_curvature_compare.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate measuring curvature numerically with Pytorch, the curvature for a single-sheeted hyperboloid is computed and compared with the theoretical values. The canonical example for curvature is a sphere, but in that case the curvarture values are the same at every point. This hyperboloid curvature is different at every point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-sheeted hyperboloid\n",
    "https://mathworld.wolfram.com/One-SheetedHyperboloid.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mathworld.wolfram.com/images/eps-gif/Hyperboloid1Sheeted1_500.gif) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When oriented along the z-axis, the one-sheeted circular hyperboloid with skirt radius $a$ has a Cartesian equation\n",
    "\n",
    "$$\\frac{x^2}{a^2} + \\frac{y^2}{a^2} - \\frac{z^2}{c^2} = 1$$\n",
    "\n",
    "and a parametric equations\n",
    "$$\n",
    "\\begin{align}\n",
    "x &= a \\sqrt{1 + u^2} \\cos v \\\\\n",
    "y &= a \\sqrt{1 + u^2} \\sin v \\\\\n",
    "z &= c * u\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore, $u = \\frac{z}{c}$ and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z &= \\sqrt{-c^2 \\left(1 - \\left(\\frac{x^2}{a^2} + \\frac{y^2}{a^2}\\right)\\right)}\\\\\n",
    "&= \\sqrt{c^2 \\left(\\frac{x^2}{a^2} + \\frac{y^2}{a^2} - 1\\right)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "The Gaussian curvature at each point is:\n",
    "\n",
    "$$K(u,v) = -\\frac{c^{2}}{\\left[c^{2} + \\left(a^{2} + c^{2}\\right)u^{2}\\right]^{2}}$$\n",
    "\n",
    "The equation to compute the mean curvature is provided by [Odehnal 2014](http://sodwana.uni-ak.ac.at/geom/mitarbeiter/odehnal/publ/krgn.pdf). For this calculation, we need the support function of the hyperboloid:\n",
    "\n",
    "$$\\frac{1}{d} = \\sqrt{\\frac{x^{2}}{a^{4}} + \\frac{y^{2}}{b^{4}} + \\frac{z^{2}}{c^{4}}}$$\n",
    "\n",
    "as well as a quadriatic function of the parameters in $x, y, z$:\n",
    "\n",
    "$$L = \\left(b^{2} - c^{2}\\right)\\frac{x^{2}}{a^{2}} + \\left(a^{2}-c^{2}\\right)\\frac{y^{2}}{b^{2}} - \\left(a^{2}+b^{2}\\right)\\frac{z^{2}}{c^{2}}$$.\n",
    "\n",
    "With these two quantities we can compute the mean curvature:\n",
    "\n",
    "$$M = \\frac{d^{3}}{2a^{2}b^{2}c^{2}}L$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import proplot as plot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "current_path = !pwd # TODO: Will this change if someone runs the notebook from elsewhere, or changes the cwd in the notebook?\n",
    "parent_path = os.path.dirname(current_path[0])\n",
    "if parent_path not in sys.path: sys.path.append(parent_path)\n",
    "\n",
    "import utils.model_handling as model_funcs\n",
    "import utils.principal_curvature as curv_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperboloid_eq(x_vals, y_vals, a, c):\n",
    "    z_sq = c**2 * (x_vals**2 / a**2 + y_vals**2 / a**2 - 1)\n",
    "    if type(x_vals) == type(torch.Tensor()):\n",
    "        return torch.sqrt_(z_sq)\n",
    "    else:\n",
    "        return np.sqrt(z_sq)\n",
    "    \n",
    "def hyperboloid_mesh(a, c, step_size, num_points):\n",
    "    pt_range = (num_points - 1) * step_size\n",
    "    start_pt = 0 - pt_range / 2\n",
    "    end_pt = 0 + pt_range / 2\n",
    "    x_pts = np.linspace(start_pt, end_pt, num_points)\n",
    "    y_pts = np.linspace(start_pt, end_pt, num_points)\n",
    "    x_mesh, y_mesh = np.meshgrid(x_pts, y_pts)\n",
    "    return x_mesh, y_mesh\n",
    "\n",
    "def hyperboloid(a, c, step_size, num_points):\n",
    "    \"\"\"generate single sheet hyperboloid\"\"\"\n",
    "    x_mesh, y_mesh = hyperboloid_mesh(a, c, step_size, num_points)\n",
    "    z_vals = hyperboloid_eq(x_mesh, y_mesh, a, c)\n",
    "    return x_mesh, y_mesh, z_vals\n",
    "\n",
    "class pytorch_hyperboloid(nn.Module):\n",
    "    def __init__(self, a, c):\n",
    "        super(pytorch_hyperboloid, self).__init__()\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "\n",
    "    def forward(self, data):\n",
    "        z_vals = hyperboloid_eq(x_vals=data[:, 0], y_vals=data[:, 1], a=self.a, c=self.c)\n",
    "        return z_vals.reshape((data.shape[0], 1)) #1 neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_pt_grad_hess(model, x_pt, y_pt, device, sr1_kwargs):\n",
    "    act_func = lambda image: model_funcs.unit_activation_and_gradient(model, image, target_neuron=0)\n",
    "    x_tensor = torch.tensor([x_pt, y_pt], dtype=torch.float).to(device)[None, :]\n",
    "    x = torch.autograd.Variable(x_tensor, requires_grad=True)\n",
    "    z, pt_grad = act_func(x)\n",
    "    pt_hess = curv_funcs.sr1_hessian(act_func, x, **sr1_kwargs)\n",
    "    return pt_grad, pt_hess\n",
    "    \n",
    "def numeric_grad_hess(model, x_vals, y_vals, device, sr1_kwargs):\n",
    "    grad = torch.zeros(x_vals.shape + (2,)).to(device)\n",
    "    hess = torch.zeros(x_vals.shape + (4,)).to(device)\n",
    "    for x_idx in tqdm(range(len(x_vals[0, :])), leave=True):\n",
    "        for y_idx in range(len(y_vals[0, :])):\n",
    "            pt_grad, pt_hess = numeric_pt_grad_hess(\n",
    "                model, x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], device, kwargs)\n",
    "            grad[x_idx, y_idx, :] = pt_grad\n",
    "            hess[x_idx, y_idx, :] = pt_hess.flatten()\n",
    "    return grad, hess\n",
    "\n",
    "def autodiff_pt_grad_hess(x_pt, y_pt, a, c, device='cpu'):\n",
    "    x_tensor = torch.tensor([x_pt, y_pt], dtype=torch.float64).to(device)\n",
    "    x = torch.autograd.Variable(x_tensor, requires_grad=True).to(device)\n",
    "    z = hyperboloid_eq(x_vals=x[0], y_vals=x[1], a=a, c=c)\n",
    "    x_1grad, = torch.autograd.grad(z, x, create_graph=True, retain_graph=True)\n",
    "    x_2grad0, = torch.autograd.grad(x_1grad[0], x, create_graph=True)\n",
    "    x_2grad1, = torch.autograd.grad(x_1grad[1], x, create_graph=True)\n",
    "    x_2grad = torch.cat((x_2grad0, x_2grad1), dim=0)\n",
    "    return x_1grad, x_2grad\n",
    "\n",
    "def autodiff_grad_hess(x_vals, y_vals, a, c, device):\n",
    "    grad = torch.zeros(x_vals.shape + (2,)).to(device)\n",
    "    hess = torch.zeros(x_vals.shape + (4,)).to(device)\n",
    "    for x_idx in tqdm(range(len(x_vals[0, :])), leave=True):\n",
    "        for y_idx in range(len(y_vals[0, :])):\n",
    "            x_1grad, x_2grad = autodiff_pt_grad_hess(x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], a, c, device)\n",
    "            grad[x_idx, y_idx, :] = x_1grad\n",
    "            hess[x_idx, y_idx, :] = x_2grad\n",
    "    return grad, hess\n",
    "\n",
    "def curvature_points(grad, hess, device):\n",
    "    gauss_curvature = np.zeros([len(grad), len(grad)])\n",
    "    mean_curvature = np.zeros([len(grad), len(grad)])\n",
    "    np_grad = grad.detach().cpu().numpy()\n",
    "    for x_idx in range(len(grad)):\n",
    "        for y_idx in range(len(grad)):\n",
    "            if not np.isnan(np_grad[x_idx, y_idx, 0]):\n",
    "                pt_grad = grad[x_idx, y_idx, :]\n",
    "                pt_hess = hess[x_idx, y_idx, :].reshape((2,2))\n",
    "                shape_operator, principal_curvatures, principal_directions = curv_funcs.local_response_curvature(pt_grad, pt_hess)\n",
    "                gauss_curvature[x_idx, y_idx] = np.prod(principal_curvatures.detach().cpu().numpy())\n",
    "                mean_curvature[x_idx, y_idx] = np.mean(principal_curvatures.detach().cpu().numpy())\n",
    "                # use trace & determinant\n",
    "    return gauss_curvature, mean_curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Change `kwargs['n_points']` and `num_points` to decrease runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the Hessian points for 1 of the hyperboloid points\n",
    "# TODO: run for smaller & smaller & check difference to analytic result\n",
    "kwargs = {}\n",
    "kwargs['distance'] = 2e-4\n",
    "kwargs['n_points'] = 2e3 # number of points to use to estimate the hessian\n",
    "kwargs['learning_rate'] = 5e-2\n",
    "kwargs['random_walk'] = False\n",
    "kwargs['return_points'] = False\n",
    "kwargs['progress'] = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "a = np.sqrt(.01)\n",
    "c = np.sqrt(.2)\n",
    "num_points = 15 # number of hyperboloid samples\n",
    "step_size = .125 / 6 # = 0.0208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals, y_vals, z_vals = hyperboloid(a, c, step_size, num_points)\n",
    "valid_z_indices = np.nonzero(np.logical_not(np.isnan(z_vals)))\n",
    "z_vals_valid = z_vals[valid_z_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [9,9])\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#ax.contourf(x_vals, y_vals, np.abs(z_vals))\n",
    "ax.scatter(x_vals, y_vals, np.abs(z_vals), c=np.abs(z_vals_valid))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient, Hessian and curvature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pytorch_hyperboloid(a, c)\n",
    "model.to(device)\n",
    "\n",
    "grad_close = []\n",
    "hess_close = []\n",
    "hess_dist = []\n",
    "n_points = 10\n",
    "points = np.random.choice(range(len(valid_z_indices[0])), n_points, replace=False)\n",
    "for point in points:\n",
    "    x_idx = valid_z_indices[0][point]\n",
    "    y_idx = valid_z_indices[1][point]\n",
    "    est_outputs = numeric_pt_grad_hess(model, x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], device, kwargs)\n",
    "    est_pt_grad = est_outputs[0].detach().cpu().numpy()\n",
    "    est_pt_hess = est_outputs[1].detach().cpu().numpy().flatten()\n",
    "\n",
    "    autodiff_outputs = autodiff_pt_grad_hess(x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], a, c, device)\n",
    "    exact_pt_grad = autodiff_outputs[0].data.cpu().numpy()\n",
    "    exact_pt_hess = autodiff_outputs[1].data.cpu().numpy()\n",
    "    \n",
    "    pt_grad_close = np.allclose(exact_pt_grad[np.logical_not(np.isnan(exact_pt_grad))], est_pt_grad[np.logical_not(np.isnan(est_pt_grad))])\n",
    "    pt_hess_close = np.allclose(exact_pt_hess[np.logical_not(np.isnan(exact_pt_hess))], est_pt_hess[np.logical_not(np.isnan(est_pt_hess))])\n",
    "    pt_hess_dist = np.sqrt(np.sum((est_pt_hess - exact_pt_hess)**2))\n",
    "    \n",
    "    grad_close.append(pt_grad_close)\n",
    "    hess_close.append(pt_hess_close)\n",
    "    hess_dist.append(pt_hess_dist)\n",
    "\n",
    "print(f'Grads are close: {grad_close}')\n",
    "print(f'Hessians are close: {hess_close}')\n",
    "print(f'Hessian distance: {[np.round(dist, 3) for dist in hess_dist]}')\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shuffles = 5\n",
    "auto_rms_error = 0\n",
    "numeric_rms_error = 0\n",
    "for shuffle_idx in tqdm(range(num_shuffles)):\n",
    "    np.random.shuffle(points)\n",
    "    x_idx = valid_z_indices[0][points[0, ...]]\n",
    "    y_idx = valid_z_indices[1][points[0, ...]]\n",
    "    tmp_kwargs = kwargs.copy()\n",
    "    tmp_kwargs['progress'] = False\n",
    "    est_outputs = numeric_pt_grad_hess(model, x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], device, tmp_kwargs)\n",
    "    est_pt_grad = est_outputs[0]\n",
    "    est_pt_hess = est_outputs[1].reshape(2, 2).double()\n",
    "    autodiff_outputs = autodiff_pt_grad_hess(x_vals[x_idx, y_idx], y_vals[x_idx, y_idx], a, c, device)\n",
    "    exact_pt_grad = autodiff_outputs[0]\n",
    "    exact_pt_hess = autodiff_outputs[1].reshape(2, 2)\n",
    "    numpy_data = []\n",
    "    for point in points:\n",
    "        x_idx = valid_z_indices[0][point]\n",
    "        y_idx = valid_z_indices[1][point]\n",
    "        x_data = x_vals[x_idx, y_idx]\n",
    "        y_data = y_vals[x_idx, y_idx]\n",
    "        numpy_data.append(np.stack([x_data, y_data], axis=0))\n",
    "    torch_data =  torch.from_numpy(np.stack(numpy_data, axis=0)).to(device)\n",
    "    f = lambda x: model_funcs.unit_activation_and_gradient(model, x, target_neuron=0)\n",
    "    auto_hess_approximation = curv_funcs.hessian_approximate_response(f, torch_data, exact_pt_hess)\n",
    "    numeric_hess_approximation = curv_funcs.hessian_approximate_response(f, torch_data, est_pt_hess)\n",
    "    model_outputs = model_funcs.unit_activation(model, torch_data, target_neuron=0)\n",
    "    auto_rms_error += torch.sqrt((auto_hess_approximation - model_outputs)**2)\n",
    "    numeric_rms_error += torch.sqrt((numeric_hess_approximation - model_outputs)**2)\n",
    "numeric_rms_error = numeric_rms_error / num_shuffles\n",
    "auto_rms_error = auto_rms_error / num_shuffles\n",
    "\n",
    "print(f'numeric estimation method RMS error = {numeric_rms_error.mean():.4f}')\n",
    "print(f'autodiff method RMS error = {auto_rms_error.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs['progress'] = False\n",
    "numeric_grad, numeric_hess = numeric_grad_hess(model, x_vals, y_vals, device, kwargs) # about 1k points / min on a gpu\n",
    "np_numeric_grad = numeric_grad.detach().cpu().numpy().copy()\n",
    "np_numeric_hess = numeric_hess.detach().cpu().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_gauss_curvature, numeric_mean_curvature = curvature_points(numeric_grad, numeric_hess, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autodiff_grad, autodiff_hess = autodiff_grad_hess(x_vals, y_vals, a, c, device)\n",
    "autodiff_gauss_curvature, autodiff_mean_curvature = curvature_points(autodiff_grad, autodiff_hess, device)\n",
    "np_autodiff_grad = autodiff_grad.detach().cpu().numpy()\n",
    "np_autodiff_hess = autodiff_hess.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autodiff_grad_valid = np_autodiff_grad[np.logical_not(np.isnan(np_autodiff_grad))]\n",
    "numeric_grad_valid = np_numeric_grad[np.logical_not(np.isnan(np_numeric_grad))]\n",
    "autodiff_hess_valid = np_autodiff_hess[np.logical_not(np.isnan(np_autodiff_hess))]\n",
    "numeric_hess_valid = np_numeric_hess[np.logical_not(np.isnan(np_numeric_hess))]\n",
    "grads_close = np.allclose(autodiff_grad_valid, numeric_grad_valid)\n",
    "print(f'Grads are close: {grads_close}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptx = num_points//3; pty = num_points//3\n",
    "\n",
    "vmin = np.min([np.min(autodiff_hess_valid), np.min(numeric_hess_valid)])\n",
    "vmax = np.max([np.max(autodiff_hess_valid), np.max(numeric_hess_valid)])\n",
    "hess_diff = np_autodiff_hess - np_numeric_hess\n",
    "hess_diff[np.isnan(hess_diff)] = 0\n",
    "mean_hess_diff = np.mean(hess_diff, axis=(0,1)).reshape(2,2)\n",
    "\n",
    "fig, axs = plot.subplots(nrows=1, ncols=3, sharex=False,  sharey=False)\n",
    "mappable = axs[0].imshow(np_numeric_hess[ptx, pty, :].reshape(2,2), vmin=vmin, vmax=vmax)\n",
    "axs[0].colorbar(mappable)\n",
    "axs[0].format(title=f\"Numeric approximation of the\\nHessian at the point [{ptx}, {pty}]\")\n",
    "mappable = axs[1].imshow(np_autodiff_hess[ptx, pty, :].reshape(2,2), vmin=vmin, vmax=vmax)\n",
    "axs[1].colorbar(mappable)\n",
    "axs[1].format(title=f\"Autodiff Hessian at the point [{ptx}, {pty}]\")\n",
    "mappable = axs[2].imshow(mean_hess_diff)\n",
    "axs[2].colorbar(mappable)\n",
    "axs[2].format(title='Mean Hessian difference across all points')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic Gaussian curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = z_vals / c # parametric formulation\n",
    "analytic_gauss_curvature = -c**2 / (c**2 + (a**2 + c**2) * u**2)**2\n",
    "\n",
    "b = a # equal curvature on each axis\n",
    "d = 1 / np.sqrt((x_vals**2 / a**4) + (y_vals**2 / b**4) + (z_vals**2 / c**4)) # support function\n",
    "L = (b**2 - c**2) * (x_vals**2 / a**2) + (a**2 - c**2) * (y_vals**2 / b**2) - (a**2 + b**2) * (z_vals**2 / c**2)\n",
    "analytic_mean_curvature = (d**3 / (2 * a**2 * b**2 * c**2)) * L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of points near the origin have an imaginary z value and are given curvature = 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of autodiff points with 0 Gaussian curvature = {sum(autodiff_gauss_curvature.flatten()==0)}\")\n",
    "print(f\"Number of numeric estimated points with 0 Gaussian curvature = {sum(numeric_gauss_curvature.flatten()==0)}\")\n",
    "print(f\"Number of analytic points with 0 Gaussian curvature = {sum(analytic_gauss_curvature.flatten()==0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "axs[0].scatter(analytic_gauss_curvature.flatten(), autodiff_gauss_curvature.flatten(), s=4, c='k')\n",
    "valid_analytic = analytic_gauss_curvature.flatten()[np.logical_not(np.isnan(analytic_gauss_curvature.flatten()))]\n",
    "valid_computed = autodiff_gauss_curvature.flatten()[np.logical_not(np.isnan(analytic_gauss_curvature.flatten()))]\n",
    "slope, intercept = np.polyfit(valid_analytic, valid_computed, 1)\n",
    "predicted_ys = [slope * curvature + intercept for curvature in valid_analytic]\n",
    "axs[0].plot(valid_analytic, predicted_ys, 'r')\n",
    "axs[0].format(\n",
    "    title = f\"Autodiff method\\nslope={slope:.4f}\",\n",
    "    xlabel = 'Analytic curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estimate of curvature',\n",
    "    fontsize = 16,\n",
    ")\n",
    "\n",
    "axs[1].scatter(analytic_gauss_curvature.flatten(), numeric_gauss_curvature.flatten(), s=4, c='k')\n",
    "valid_computed = numeric_gauss_curvature.flatten()[np.logical_not(np.isnan(analytic_gauss_curvature.flatten()))]\n",
    "slope, intercept = np.polyfit(valid_analytic, valid_computed, 1)\n",
    "predicted_ys = [slope * curvature + intercept for curvature in valid_analytic]\n",
    "axs[1].plot(valid_analytic, predicted_ys, 'r')\n",
    "axs[1].format(\n",
    "    title = f'Numeric estimation method\\nslope={slope:.4f}',\n",
    "    xlabel = 'Analytic curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estimate of curvature',\n",
    "    fontsize = 16,\n",
    ")\n",
    "axs.format(suptitle='Gaussian Curvature')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "\n",
    "axs[0].scatter(analytic_mean_curvature.flatten(), autodiff_mean_curvature.flatten(), s=4, c='k')\n",
    "valid_analytic = analytic_mean_curvature.flatten()[np.logical_not(np.isnan(analytic_mean_curvature.flatten()))]\n",
    "valid_computed = autodiff_mean_curvature.flatten()[np.logical_not(np.isnan(analytic_mean_curvature.flatten()))]\n",
    "slope, intercept = np.polyfit(valid_analytic, valid_computed, 1)\n",
    "predicted_ys = [slope * curvature + intercept for curvature in valid_analytic]\n",
    "axs[0].plot(valid_analytic, predicted_ys, 'r')\n",
    "axs[0].format(\n",
    "    title = f'Autodiff method\\nslope={slope:.4f}',\n",
    "    xlabel = 'Analytic mean curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estiamte of curvature',\n",
    "    fontsize = 16,\n",
    ")\n",
    "\n",
    "axs[1].scatter(analytic_mean_curvature.flatten(), numeric_mean_curvature.flatten(), s=4, c='k')\n",
    "valid_computed = numeric_mean_curvature.flatten()[np.logical_not(np.isnan(analytic_mean_curvature.flatten()))]\n",
    "slope, intercept = np.polyfit(valid_analytic, valid_computed, 1)\n",
    "predicted_ys = [slope * curvature + intercept for curvature in valid_analytic]\n",
    "axs[1].plot(valid_analytic, predicted_ys, 'r')\n",
    "axs[1].format(\n",
    "    title = f'Numeric estimation method\\nslope={slope:.4f}',\n",
    "    xlabel = 'Analytic mean curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estimate of curvature',\n",
    "    fontsize = 16,\n",
    ")\n",
    "axs.format(suptitle='Mean Curvature')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "axs[0].scatter(np.abs(analytic_gauss_curvature.flatten()), np.abs(autodiff_gauss_curvature.flatten()), s=4, c='k')\n",
    "axs[0].format(\n",
    "    title = 'Autodiff method',\n",
    "    xlabel = 'Analytic curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estimate of curvature',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log'\n",
    ")\n",
    "\n",
    "axs[1].scatter(np.abs(analytic_gauss_curvature.flatten()), np.abs(numeric_gauss_curvature.flatten()), s=4, c='k')\n",
    "axs[1].format(\n",
    "    title = 'Numeric estimation method',\n",
    "    xlabel = 'Analytic curvautre, single-sheet hyperboloid',\n",
    "    ylabel = 'Estimate of curvature',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log'\n",
    ")\n",
    "\n",
    "axs.format(suptitle='Gaussian curvature (log scale)')\n",
    "#axs.set_aspect('equal')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autodiff_largest_deviation = np.max(np.abs((analytic_gauss_curvature[np.logical_not(np.isnan(np_autodiff_grad[:,:,0]))].flatten() - autodiff_gauss_curvature[np.logical_not(np.isnan(np_autodiff_grad[:,:,0]))].flatten())))\n",
    "numeric_largest_deviation = np.max(np.abs((analytic_gauss_curvature[np.logical_not(np.isnan(np_numeric_grad[:,:,0]))].flatten() - numeric_gauss_curvature[np.logical_not(np.isnan(np_numeric_grad[:,:,0]))].flatten())))\n",
    "print(f'Largest deviation from the analytic result for autodiff method (Gaussian): {autodiff_largest_deviation}')\n",
    "print(f'Largest deviation from the analytic result for numeric estimation method (Gaussian): {numeric_largest_deviation}')\n",
    "\n",
    "autodiff_largest_deviation = np.max(np.abs((analytic_mean_curvature[np.logical_not(np.isnan(np_autodiff_grad[:,:,0]))].flatten() - autodiff_mean_curvature[np.logical_not(np.isnan(np_autodiff_grad[:,:,0]))].flatten())))\n",
    "numeric_largest_deviation = np.max(np.abs((analytic_mean_curvature[np.logical_not(np.isnan(np_numeric_grad[:,:,0]))].flatten() - numeric_mean_curvature[np.logical_not(np.isnan(np_numeric_grad[:,:,0]))].flatten())))\n",
    "print(f\"\\nLargest deviation from the analytic result for James' method (Mean): {autodiff_largest_deviation}\")\n",
    "print(f\"Largest deviation from the analytic result for Dylan's method (Mean): {numeric_largest_deviation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "\n",
    "axs[0].scatter(np.abs(autodiff_gauss_curvature.flatten()),\n",
    "               np.abs(analytic_gauss_curvature.flatten() - autodiff_gauss_curvature.flatten()),\n",
    "               s=4, c='k')\n",
    "axs[0].format(\n",
    "    title = 'Autodiff method',\n",
    "    xlabel = 'Predicted curvature',\n",
    "    ylabel = 'Prediction error',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log',\n",
    "    #ylim = [1e-18, 1e-12]\n",
    ")\n",
    "axs[1].scatter(np.abs(numeric_gauss_curvature.flatten()),\n",
    "               np.abs(analytic_gauss_curvature.flatten() - numeric_gauss_curvature.flatten()),\n",
    "               s=4, c='k')\n",
    "axs[1].format(\n",
    "    title = 'Numeric estimation method',\n",
    "    xlabel = 'Predicted curvature',\n",
    "    ylabel = 'Prediction error',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log',\n",
    "    #ylim = [1e-18, 1e-12]\n",
    ")\n",
    "axs.format(suptitle='Gaussian curvature (absolute value)')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "\n",
    "axs[0].scatter(np.abs(autodiff_gauss_curvature.flatten()),\n",
    "    np.abs(analytic_gauss_curvature.flatten() - autodiff_gauss_curvature.flatten()) / np.abs(autodiff_gauss_curvature.flatten()),\n",
    "    s=4, c='k')\n",
    "axs[0].format(\n",
    "    title = 'Autodiff method',\n",
    "    xlabel = 'Predicted curvature',\n",
    "    ylabel = 'Prediction error / analytic curvature',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log',\n",
    "    #ylim = [1e-16, 1e-12]\n",
    ")\n",
    "axs[1].scatter(np.abs(numeric_gauss_curvature.flatten()),\n",
    "    np.abs(analytic_gauss_curvature.flatten() - numeric_gauss_curvature.flatten()) / np.abs(numeric_gauss_curvature.flatten()),\n",
    "    s=4, c='k')\n",
    "axs[1].format(\n",
    "    title = 'Numeric estimation method',\n",
    "    xlabel = 'Predicted curvature',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    xscale = 'log',\n",
    "    #ylim = [1e-16, 1e-12]\n",
    ")\n",
    "axs.format(suptitle='Gaussian curvature (absolute value)')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2, sharey=False)\n",
    "\n",
    "axs[0].scatter(z_vals.flatten(),\n",
    "    np.abs(analytic_gauss_curvature.flatten() - autodiff_gauss_curvature.flatten()) / np.abs(autodiff_gauss_curvature.flatten()),\n",
    "    s=4, c='k')\n",
    "axs[0].format(\n",
    "    title = 'Autodiff method',\n",
    "    xlabel = 'Function values (z)',\n",
    "    ylabel = 'Prediction error / analytic curvature',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    #ylim = [1e-16, 1e-12]\n",
    ")\n",
    "axs[1].scatter(z_vals.flatten(),\n",
    "    np.abs(analytic_gauss_curvature.flatten() - numeric_gauss_curvature.flatten()) / np.abs(numeric_gauss_curvature.flatten()),\n",
    "    s=4, c='k')\n",
    "axs[1].format(\n",
    "    title = 'Numeric estimation method',\n",
    "    xlabel = 'Function values (z)',\n",
    "    fontsize = 16,\n",
    "    yscale = 'log',\n",
    "    #ylim = [1e-16, 1e-12]\n",
    ")\n",
    "axs.format(suptitle='Gaussian curvature (absolute value)')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=1, ncols=2)\n",
    "autodiff_error = analytic_gauss_curvature.flatten() - autodiff_gauss_curvature.flatten()\n",
    "autodiff_error_norm = autodiff_error / analytic_gauss_curvature.flatten()\n",
    "axs[0].hist(autodiff_error_norm, bins=50)\n",
    "axs[0].format(\n",
    "    title = 'Autodiff method',\n",
    "    ylabel = 'count',\n",
    "    fontsize = 14\n",
    ")\n",
    "numeric_error = analytic_gauss_curvature.flatten() - numeric_gauss_curvature.flatten()\n",
    "numeric_error_norm = numeric_error / analytic_gauss_curvature.flatten()\n",
    "axs[1].hist(numeric_error_norm, bins=50)\n",
    "axs[1].format(\n",
    "    title = 'Numeric estimation method',\n",
    "    ylabel = 'count',\n",
    "    fontsize = 14\n",
    ")\n",
    "axs.format(\n",
    "    suptitle = 'Hist of (error in numerical curvautre) / (analytic curvature)',\n",
    "    xlabel = '\\nRatio of numerical curvature error to analytic curvature',\n",
    ")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
